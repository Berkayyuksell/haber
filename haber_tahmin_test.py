import pandas as pd
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix
import pickle
import os
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm.auto import tqdm # EÄŸitim dÃ¶ngÃ¼sÃ¼nde ilerleme Ã§ubuÄŸu iÃ§in

# --- BERT Model Part ---

# GPU/MPS/CPU kullanÄ±mÄ±nÄ± kontrol eden fonksiyon
def get_device():
    if torch.cuda.is_available():
        device = torch.device("cuda")
        gpu_count = torch.cuda.device_count()
        gpu_name = torch.cuda.get_device_name(0)
        print(f"ğŸš€ GPU bulundu! {gpu_count} adet kullanÄ±labilir GPU.")
        print(f"ğŸ”¥ KullanÄ±lan GPU: {gpu_name}")
        if hasattr(torch.cuda, 'get_device_properties'):
            total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"ğŸ“Š GPU bellek: {total_memory:.2f} GB")
    elif torch.backends.mps.is_available(): # Apple Silicon (M1/M2) iÃ§in MPS kontrolÃ¼
        device = torch.device("mps")
        print("ğŸ Apple Silicon (MPS) bulundu! GPU hÄ±zlandÄ±rmasÄ± kullanÄ±lacak.")
        # MPS iÃ§in bellek bilgisi doÄŸrudan alÄ±namayabilir, sistem bilgisi daha geneldir.
    else:
        device = torch.device("cpu")
        print("âš ï¸ GPU veya MPS bulunamadÄ±, CPU kullanÄ±lacak (Bu iÅŸlem Ã§ok yavaÅŸ olabilir!)")
        import multiprocessing
        cpu_count = multiprocessing.cpu_count()
        print(f"ğŸ’» CPU Ã§ekirdek sayÄ±sÄ±: {cpu_count}")
    
    return device

class NewsDataset(Dataset):
    """BERT modeli iÃ§in veri seti sÄ±nÄ±fÄ±."""
    def __init__(self, texts, labels, tokenizer, max_len=128):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_len = max_len
        
    def __len__(self):
        return len(self.texts)
        
    def __getitem__(self, idx):
        text = str(self.texts[idx])
        label = self.labels[idx]
        
        encoding = self.tokenizer.encode_plus(
            text,
            add_special_tokens=True,
            max_length=self.max_len,
            return_token_type_ids=False,
            padding='max_length',
            truncation=True,
            return_attention_mask=True,
            return_tensors='pt'
        )
        
        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(label, dtype=torch.long)
        }

def load_data_from_csv(file_path='total_cleaned_lowercase.csv'):
    """CSV dosyasÄ±ndan veri yÃ¼kler."""
    try:
        df = pd.read_csv(file_path)
        print(f"CSV dosyasÄ±ndan {len(df)} kayÄ±t baÅŸarÄ±yla yÃ¼klendi.")
        
        # SÃ¼tun isimlerini kontrol et
        if 'text' not in df.columns or 'category' not in df.columns:
            # En iyi tahmin: Ä°lk iki sÃ¼tun text ve category olabilir
            if len(df.columns) >= 2:
                # KullanÄ±cÄ±dan onay almak daha iyi olabilir veya belirli bir varsayÄ±mda bulunmak
                print("âš ï¸ 'text' veya 'category' sÃ¼tunlarÄ± bulunamadÄ±. Ä°lk sÃ¼tunu 'text', ikinci sÃ¼tunu 'category' olarak kabul ediliyor.")
                df = df.rename(columns={df.columns[0]: 'text', df.columns[1]: 'category'})
            else:
                raise ValueError("CSV dosyasÄ±nda 'text' ve 'category' sÃ¼tunlarÄ± veya yeterli sÃ¼tun bulunmuyor.")
        
        # NaN deÄŸerleri kontrol et ve dÃ¼ÅŸÃ¼r
        initial_rows = len(df)
        df.dropna(subset=['text', 'category'], inplace=True)
        if len(df) < initial_rows:
            print(f"ğŸ§¹ NaN deÄŸerler iÃ§eren {initial_rows - len(df)} satÄ±r dÃ¼ÅŸÃ¼rÃ¼ldÃ¼.")

        # Kategori deÄŸerlerini kontrol et
        print(f"Kategoriler: {df['category'].unique()}")
        print(f"Kategori daÄŸÄ±lÄ±mÄ±:\n{df['category'].value_counts()}")
        
        return df
    
    except FileNotFoundError:
        print(f"âŒ Hata: '{file_path}' dosyasÄ± bulunamadÄ±. LÃ¼tfen dosya yolunu kontrol edin.")
        return None
    except pd.errors.EmptyDataError:
        print(f"âŒ Hata: '{file_path}' dosyasÄ± boÅŸ.")
        return None
    except Exception as e:
        print(f"âŒ CSV dosyasÄ± yÃ¼klenirken beklenmeyen bir hata oluÅŸtu: {str(e)}")
        return None

def balance_dataset(df, samples_per_category=None):
    """Veri setini her kategoriden belirli sayÄ±da Ã¶rnek iÃ§erecek ÅŸekilde dengele.
    samples_per_category None ise, en az Ã¶rneÄŸe sahip kategorinin sayÄ±sÄ±na gÃ¶re dengeleme yapÄ±lÄ±r.
    """
    balanced_df = pd.DataFrame()
    
    if samples_per_category is None:
        min_samples = df['category'].value_counts().min()
        samples_per_category = min_samples
        print(f"â„¹ï¸ `samples_per_category` belirtilmedi. En az Ã¶rneÄŸe sahip kategori ({df['category'].value_counts().idxmax()}) sayÄ±sÄ± ({min_samples}) kullanÄ±lacak.")
        
    print(f"ğŸ“Š Her kategori iÃ§in hedeflenen Ã¶rnek sayÄ±sÄ±: {samples_per_category}")

    for category in df['category'].unique():
        category_df = df[df['category'] == category]
        if len(category_df) > samples_per_category:
            # Rastgele Ã¶rnekleme
            category_df = category_df.sample(n=samples_per_category, random_state=42)
        elif len(category_df) < samples_per_category:
            print(f"âš ï¸ Kategori '{category}' iÃ§in yeterli Ã¶rnek yok ({len(category_df)}/{samples_per_category}). Mevcut tÃ¼m Ã¶rnekler kullanÄ±lacak.")
        balanced_df = pd.concat([balanced_df, category_df])
    
    # KarÄ±ÅŸÄ±k hale getir
    balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)

    print(f"ğŸ“Š DengelenmiÅŸ veri seti boyutu: {len(balanced_df)} Ã¶rnek")
    print(f"ğŸ“Š Kategori daÄŸÄ±lÄ±mÄ± (Dengeleme sonrasÄ±):\n{balanced_df['category'].value_counts()}")
    
    return balanced_df

def evaluate_model(model, data_loader, device, label_encoder, plot_confusion_matrix=False):
    """Model performansÄ±nÄ± deÄŸerlendir ve metrikleri hesapla."""
    model.eval()
    all_predictions = []
    all_labels = []
    
    with torch.no_grad():
        for batch in tqdm(data_loader, desc="DeÄŸerlendirme"):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)
            
            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask
            )
            
            _, predicted = torch.max(outputs.logits, 1)
            all_predictions.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    
    # Metrikleri hesapla
    accuracy = accuracy_score(all_labels, all_predictions)
    
    # SÄ±nÄ±flandÄ±rma raporu
    report = classification_report(
        all_labels, 
        all_predictions, 
        target_names=label_encoder.classes_, 
        output_dict=True, 
        zero_division=0 # Desteklenmeyen sÄ±nÄ±flar iÃ§in 0 atar
    )
    
    precision = report['weighted avg']['precision']
    recall = report['weighted avg']['recall']
    f1 = report['weighted avg']['f1-score']
    
    # Kategori bazlÄ± metrikler
    category_metrics = {
        category: {
            'precision': report[category]['precision'],
            'recall': report[category]['recall'],
            'f1': report[category]['f1-score'],
            'support': report[category]['support']
        } for category in label_encoder.classes_
    }

    if plot_confusion_matrix:
        cm = confusion_matrix(all_labels, all_predictions)
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", 
                    xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
        plt.title('KarmaÅŸÄ±klÄ±k Matrisi')
        plt.xlabel('Tahmin Edilen Etiket')
        plt.ylabel('GerÃ§ek Etiket')
        plt.show()
    
    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'category_metrics': category_metrics,
        'all_predictions': all_predictions,
        'all_labels': all_labels # KarmaÅŸÄ±klÄ±k matrisi iÃ§in
    }

def train_model(df):
    text_col = 'text'
    label_col = 'category'
    
    df = balance_dataset(df, samples_per_category=None) 
    
    # Label encoding
    le = LabelEncoder()
    df['encoded_category'] = le.fit_transform(df[label_col])
    num_labels = len(le.classes_)
    
    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(
        df[text_col].values, 
        df['encoded_category'].values,
        test_size=0.2,
        random_state=42,
        stratify=df['encoded_category'] # Kategorilere gÃ¶re stratify et
    )
    
    # Tokenizer yÃ¼kle
    tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-cased')
    
    # Cihaz belirlemesi ve batch boyutu
    device = get_device()
    # M2 MacBook Air iÃ§in MPS kullanÄ±lÄ±yorsa daha bÃ¼yÃ¼k batch boyutu deneyebiliriz
    batch_size = 32 if str(device) == 'mps' else (16 if str(device) == 'cuda' else 8)
    # Metin uzunluÄŸunu gÃ¶z Ã¶nÃ¼nde bulundurarak max_len ayarÄ±
    max_len = 128 # Haber baÅŸlÄ±klarÄ± iÃ§in yeterli, daha uzun metinler iÃ§in 256 veya 512
    
    print(f"âœ… Batch boyutu: {batch_size}")
    print(f"âœ… Max token uzunluÄŸu: {max_len}")
    print(f"ğŸ“Š EÄŸitim seti boyutu: {len(X_train)} Ã¶rnek")
    print(f"ğŸ“Š Test seti boyutu: {len(X_test)} Ã¶rnek")
    
    # Veri setlerini oluÅŸtur
    train_dataset = NewsDataset(X_train, y_train, tokenizer, max_len=max_len)
    test_dataset = NewsDataset(X_test, y_test, tokenizer, max_len=max_len)
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=os.cpu_count()//2 if str(device) == 'cpu' else 0)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=os.cpu_count()//2 if str(device) == 'cpu' else 0)
    
    # Model
    model = BertForSequenceClassification.from_pretrained(
        'dbmdz/bert-base-turkish-cased',
        num_labels=num_labels
    )
    
    # Cihaza taÅŸÄ±
    model.to(device)
    print(f"â„¹ï¸ Model {device} Ã¼zerinde eÄŸitiliyor...")
    
    # Optimizer ve Learning Rate Scheduler
    optimizer = AdamW(model.parameters(), lr=2e-5) 
    epochs = 3 
    total_steps = len(train_loader) * epochs
    
    scheduler = get_linear_schedule_with_warmup(
        optimizer,
        num_warmup_steps=0, # IsÄ±nma adÄ±mÄ± yok
        num_training_steps=total_steps
    )
    
    print(f"ğŸ”„ EÄŸitim baÅŸlÄ±yor: {epochs} epoch, toplam {total_steps} batch")
    
    best_f1 = -1 # F1 skoru 0 ile 1 arasÄ±nda olduÄŸu iÃ§in -1 ile baÅŸlat
    best_model_state = None
    
    # EÄŸitim geÃ§miÅŸi
    train_losses = []
    eval_f1_scores = []
    
    for epoch in range(epochs):
        model.train()
        total_loss = 0
        
        print(f"\n--- Epoch {epoch+1}/{epochs} ---")
        
        for batch in tqdm(train_loader, desc=f"Epoch {epoch+1} EÄŸitimi"):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)
            
            optimizer.zero_grad()
            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                labels=labels
            )
            
            loss = outputs.loss
            total_loss += loss.item()
            
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # Gradyan patlamasÄ±nÄ± Ã¶nlemek iÃ§in
            optimizer.step()
            scheduler.step()
            
        avg_loss = total_loss / len(train_loader)
        train_losses.append(avg_loss)
        print(f'  Epoch {epoch+1}/{epochs} tamamlandÄ±, Ortalama loss: {avg_loss:.4f}')
        
        # Her epoch sonunda modeli deÄŸerlendir
        metrics = evaluate_model(model, test_loader, device, le, plot_confusion_matrix=False) # Her epochta Ã§izimi kapat
        eval_f1_scores.append(metrics['f1'])
        print("\nğŸ“Š Epoch DeÄŸerlendirme Metrikleri:")
        print(f"  Accuracy: {metrics['accuracy']:.4f}")
        print(f"  Precision: {metrics['precision']:.4f}")
        print(f"  Recall: {metrics['recall']:.4f}")
        print(f"  F1-Score: {metrics['f1']:.4f}")
        
        # En iyi modeli kaydet (F1 skoru bazÄ±nda)
        if metrics['f1'] > best_f1:
            best_f1 = metrics['f1']
            # Modelin durumunu kopyala
            best_model_state = model.state_dict()
            print(f"  ğŸ† Yeni en iyi model kaydedildi! (F1: {best_f1:.4f})")
    
    # En iyi modeli yÃ¼kle (eÄŸer bir iyileÅŸme olduysa)
    if best_model_state is not None:
        model.load_state_dict(best_model_state)
        print("\nâœ… En iyi model durumu yÃ¼klendi.")
    else:
        print("\nâ„¹ï¸ Modelde herhangi bir F1 skoru iyileÅŸmesi gÃ¶rÃ¼lmedi. Son epoch modeli kullanÄ±lacak.")
    
    # EÄŸitim geÃ§miÅŸini Ã§iz
    plt.figure(figsize=(12, 5))
    
    plt.subplot(1, 2, 1)
    plt.plot(range(1, epochs + 1), train_losses, marker='o')
    plt.title('EÄŸitim KaybÄ± (Training Loss) vs. Epoch')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.grid(True)

    plt.subplot(1, 2, 2)
    plt.plot(range(1, epochs + 1), eval_f1_scores, marker='o', color='green')
    plt.title('F1-Score (Test Seti) vs. Epoch')
    plt.xlabel('Epoch')
    plt.ylabel('F1-Score')
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Final deÄŸerlendirme (karmaÅŸÄ±klÄ±k matrisi ile)
    print("\nğŸ§ª Final Model DeÄŸerlendirmesi:")
    final_metrics = evaluate_model(model, test_loader, device, le, plot_confusion_matrix=True) # SonuÃ§larÄ± gÃ¶rselleÅŸtir
    print(f"  Accuracy: {final_metrics['accuracy']:.4f}")
    print(f"  Precision (Weighted): {final_metrics['precision']:.4f}")
    print(f"  Recall (Weighted): {final_metrics['recall']:.4f}")
    print(f"  F1-Score (Weighted): {final_metrics['f1']:.4f}")
    
    print("\nğŸ“Š Kategori BazlÄ± Metrikler:")
    for category, metrics in final_metrics['category_metrics'].items():
        print(f"\n  {category}:")
        print(f"    Precision: {metrics['precision']:.4f}")
        print(f"    Recall: {metrics['recall']:.4f}")
        print(f"    F1-Score: {metrics['f1']:.4f}")
        print(f"    Destek (Support): {metrics['support']}")
    
    # Modeli kaydet
    model_save_path = 'news_category_model'
    os.makedirs(model_save_path, exist_ok=True) # KlasÃ¶r yoksa oluÅŸtur
    model.save_pretrained(model_save_path)
    tokenizer.save_pretrained(model_save_path)
    
    # Label encoder'Ä± kaydet
    with open('label_encoder.pkl', 'wb') as f:
        pickle.dump(le, f)
    
    print(f"\nğŸ’¾ Model ve tokenizer kaydedildi: {model_save_path}")
    print(f"ğŸ’¾ Label encoder kaydedildi: label_encoder.pkl")
    
    return model, tokenizer, le

def predict_category(headline, model, tokenizer, label_encoder, device=None):
    """Verilen haber baÅŸlÄ±ÄŸÄ±nÄ±n kategorisini tahmin eder."""
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')
    
    model.to(device)
    model.eval()
    
    encoding = tokenizer.encode_plus(
        headline,
        add_special_tokens=True,
        max_length=128, # EÄŸitimde kullanÄ±lan max_len ile uyumlu olmalÄ±
        return_token_type_ids=False,
        padding='max_length',
        truncation=True,
        return_attention_mask=True,
        return_tensors='pt'
    )
    
    input_ids = encoding['input_ids'].to(device)
    attention_mask = encoding['attention_mask'].to(device)
    
    with torch.no_grad():
        outputs = model(
            input_ids=input_ids,
            attention_mask=attention_mask
        )
    
    logits = outputs.logits
    probabilities = torch.nn.functional.softmax(logits, dim=1)
    confidence, predicted = torch.max(probabilities, 1)
    predicted_category = label_encoder.inverse_transform([predicted.item()])[0]
    
    return predicted_category, confidence.item()

# --- Chatbot Class ---

class NewsCategoryBot:
    """Haber kategorisi tahmin eden chatbot sÄ±nÄ±fÄ±."""
    def __init__(self):
        self.device = get_device() # CihazÄ± baÅŸlatmada belirle
        self.model_loaded = False
        self.model = None
        self.tokenizer = None
        self.label_encoder = None
        self.categories = []
        
        self._load_model_and_tokenizer() # BaÅŸlangÄ±Ã§ta modeli yÃ¼klemeyi dene
    
    def _load_model_and_tokenizer(self):
        """KaydedilmiÅŸ modeli ve tokenizer'Ä± yÃ¼klemeye Ã§alÄ±ÅŸÄ±r."""
        model_path = 'news_category_model'
        label_encoder_path = 'label_encoder.pkl'
        
        if os.path.exists(model_path) and os.path.exists(label_encoder_path):
            try:
                print(f"ğŸ’¾ KaydedilmiÅŸ model ve tokenizer bulundu: {model_path}")
                self.model = BertForSequenceClassification.from_pretrained(model_path)
                self.tokenizer = BertTokenizer.from_pretrained(model_path)
                
                with open(label_encoder_path, 'rb') as f:
                    self.label_encoder = pickle.load(f)
                
                self.categories = list(self.label_encoder.classes_)
                print(f"ğŸ“‹ Model {len(self.categories)} farklÄ± kategori tahmin edebilir:")
                print(f"   {', '.join(self.categories)}")
                
                print("âœ… Model baÅŸarÄ±yla yÃ¼klendi!")
                self.model_loaded = True
                self.model.to(self.device) # YÃ¼klenen modeli cihaza taÅŸÄ±
            except Exception as e:
                print(f"âš ï¸ KaydedilmiÅŸ model yÃ¼klenirken hata oluÅŸtu: {str(e)}")
                print("ğŸ”„ Yeni model eÄŸitilmesi gerekebilir.")
                self.model_loaded = False
        else:
            print("âš ï¸ KaydedilmiÅŸ model veya label encoder bulunamadÄ±.")
            print("ğŸ”„ Yeni model eÄŸitilmesi gerekiyor.")
            self.model_loaded = False
    
    def train(self):
        """Modeli eÄŸit."""
        if self.model_loaded:
            print("â„¹ï¸ Model zaten yÃ¼klÃ¼ ve eÄŸitilmiÅŸ durumda. Yeniden eÄŸitmeye devam ediliyor...")
            confirm = input("EÄŸitim verileri sÄ±fÄ±rlanacak ve model yeniden eÄŸitilecek. Emin misiniz? (evet/hayÄ±r): ").lower()
            if confirm != 'evet':
                print("EÄŸitim iptal edildi.")
                return False

        print("ğŸ“Š Veri setini yÃ¼kleniyor...")
        df = load_data_from_csv()
        
        if df is not None and not df.empty:
            print("ğŸ§  Model eÄŸitimi baÅŸlÄ±yor...")
            self.model, self.tokenizer, self.label_encoder = train_model(df)
            self.categories = list(self.label_encoder.classes_)
            self.model_loaded = True
            return True
        else:
            print("âŒ CSV dosyasÄ±ndan geÃ§erli veri yÃ¼klenemedi veya veri boÅŸ. Model eÄŸitilemedi.")
            return False
    
    def predict(self, headline):
        """Haber baÅŸlÄ±ÄŸÄ±nÄ±n kategorisini tahmin et."""
        if not self.model_loaded:
            return "Model henÃ¼z eÄŸitilmedi. LÃ¼tfen Ã¶nce 'train' fonksiyonunu Ã§aÄŸÄ±rÄ±n.", 0.0
        
        category, confidence = predict_category(headline, self.model, self.tokenizer, self.label_encoder, self.device)
        return category, confidence
    
    def respond(self, user_input):
        """KullanÄ±cÄ± girdisine yanÄ±t verir."""
        user_input_lower = user_input.lower().strip()

        if user_input_lower in ["eÄŸit", "train", "egit"]:
            success = self.train()
            if success:
                return "âœ… Model eÄŸitildi ve kaydedildi."
            else:
                return "âŒ Model eÄŸitimi baÅŸarÄ±sÄ±z oldu!"
        elif user_input_lower in ["kategoriler", "categories"]:
            if self.model_loaded and self.categories:
                categories_str = ", ".join(self.categories)
                return f"ğŸ“‹ Mevcut kategoriler: {categories_str}"
            else:
                return "âŒ Model henÃ¼z eÄŸitilmedi veya kategori bilgisi yok."
        else:
            category, confidence = self.predict(user_input)
            confidence_percent = confidence * 100
            
            certainty_level = ""
            if confidence_percent >= 95:
                certainty_level = "kesinlikle"
            elif confidence_percent >= 80:
                certainty_level = "Ã§ok yÃ¼ksek olasÄ±lÄ±kla"
            elif confidence_percent >= 60:
                certainty_level = "yÃ¼ksek olasÄ±lÄ±kla"
            elif confidence_percent >= 40:
                certainty_level = "orta olasÄ±lÄ±kla"
            else:
                certainty_level = "dÃ¼ÅŸÃ¼k olasÄ±lÄ±kla"
                
            return f'ğŸ“° Tahmin edilen kategori: **{category}** (gÃ¼ven: %{confidence_percent:.2f} - {certainty_level})'

# --- Main Function ---

def main():
    """Ana program fonksiyonu."""
    print("""
    ğŸ“° HABER KATEGORÄ° TAHMÄ°N BOTU ğŸ“°
    ===============================
    
    KullanÄ±m:
    - Bir haber baÅŸlÄ±ÄŸÄ± yazÄ±n, bot kategorisini tahmin edecektir.
    - "train" veya "eÄŸit" yazarak modeli yeniden eÄŸitebilirsiniz.
    - "kategoriler" yazarak mevcut kategorileri gÃ¶rebilirsiniz.
    - "Ã§Ä±kÄ±ÅŸ" yazarak programdan Ã§Ä±kabilirsiniz.
    """)
    
    bot = NewsCategoryBot()
    
    # Model ilk baÅŸta yÃ¼klenemezse, kullanÄ±cÄ±dan eÄŸitmesini iste
    if not bot.model_loaded:
        print("\nModel hazÄ±r deÄŸil. LÃ¼tfen Ã¶nce modeli eÄŸitin veya bir baÅŸlÄ±k girin.")
        print("Modeli eÄŸitmek iÃ§in 'train' yazÄ±n.")
        
    # Chat dÃ¶ngÃ¼sÃ¼
    while True:
        user_input = input("\nğŸ“Œ Haber baÅŸlÄ±ÄŸÄ± girin (Ã§Ä±kÄ±ÅŸ iÃ§in 'Ã§Ä±kÄ±ÅŸ' yazÄ±n): ")
        
        if user_input.lower().strip() == "Ã§Ä±kÄ±ÅŸ":
            print("ğŸ‘‹ Program sonlandÄ±rÄ±lÄ±yor...")
            break
        
        response = bot.respond(user_input)
        print(response)

if __name__ == "__main__":
    main()